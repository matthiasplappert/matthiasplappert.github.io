<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Matthias Plappert</title>
    <meta name="description" content="Personal website of Matthias Plappert, a research scientist with an interest in machine learning and robotics.">

    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/font-awesome.min.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="container">
      <div class="row header">
        <div class="col-sm-4 avatar">
          <img src="images/avatar.jpg" alt="Matthias Plappert">
        </div>
        <div class="col-sm-8">
          <h1>Matthias Plappert</h1>
          <p>
            I am a research scientist with an interest in machine learning and robotics, especially deep reinforcement learning.
          </p>
          <div class="contact">
          <ul>
            <li>
              <i class="fa fa-github" aria-hidden="true"></i> <a href="https://github.com/matthiasplappert">GitHub</a>
            </li>
            <li>
              <i class="fa fa-google" aria-hidden="true"></i> <a href="https://scholar.google.com/citations?user=MHQv5YUAAAAJ">Scholar</a>
            </li>
            <li>
              <i class="fa fa-envelope" aria-hidden="true"></i> <a href="&#109;&#097;&#105;&#108;&#116;&#111;:&#109;&#097;&#116;&#116;&#104;&#105;&#097;&#115;&#112;&#108;&#097;&#112;&#112;&#101;&#114;&#116;&#064;&#109;&#101;&#046;&#099;&#111;&#109;">Email</a>
            </li>
            <li>
              <i class="fa fa-file-pdf-o" aria-hidden="true"></i> <a href="cv.pdf">CV</a>
            </li>
          </ul>
          </div>
        </div>
      </div>
      <div class="row">
        <h2>Publications</h2>
        <ul>
          <li>
            <strong>OpenAI</strong>, <a href="https://arxiv.org/abs/1808.00177">Learning Dexterous In-Hand Manipulation</a>, <em>arXiv:1808.00177</em>, August 2018 [<a href="publications/2018_OpenAI_Dexterous-Manipulation.pdf">pdf</a>, <a href="https://blog.openai.com/learning-dexterity/">blog post</a>, <a href="https://www.youtube.com/watch?v=jwSbzNHGflM">video 1</a>, <a href="https://www.youtube.com/watch?v=DKe8FumoD4E">video 2</a>, <a href="publications/2018_OpenAI_Dexterous-Manipulation.bib">bib</a>]
          </li>
          <li>
            <strong>M. Plappert</strong>, C. Mandery, and T. Asfour, <a href="https://doi.org/10.1016/j.robot.2018.07.006">Learning a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks</a>, <em>Robotics and Autonomous Systems, Vol. 109, pp. 13-26</em>, November 2018 [<a href="publications/2018_Plappert_Deep-Motion-Language-Mapping.pdf">pdf</a>, <a href="https://www.youtube.com/watch?v=2UQWOZtsg-8">video</a>, <a href="https://motion-annotation.humanoids.kit.edu/dataset">dataset</a>, <a href="https://gitlab.com/h2t/DeepMotionLanguageMapping">code</a>, <a href="publications/2018_Plappert_Deep-Motion-Language-Mapping.bib">bib</a>]
          </li>
          <li>
            <strong>M. Plappert</strong>, R. Houthooft, P. Dhariwal, S. Sidor, R.Y. Chen, X. Chen, T. Asfour, P. Abbeel, and M. Andrychowicz, <a href="https://openreview.net/forum?id=ByBAl2eAZ">Parameter Space Noise for Exploration</a>, <em>In the proceedings of the International Conference on Learning Representations (ICLR), Vancouver, Canada</em>, April 2018 [<a href="publications/2018_Plappert_Param-Noise-ICLR.pdf">pdf</a>, <a href="https://blog.openai.com/better-exploration-with-parameter-noise/">blog post</a>, <a href="https://github.com/openai/baselines">code</a>, <a href="publications/2018_Plappert_Param-Noise-ICLR.bib">bib</a>]
          </li>
          <li>
            <strong>M. Plappert</strong>, M. Andrychowicz, A. Ray, B. McGrew, B. Baker, G. Powell, J. Schneider, J. Tobin, M. Chociej, P. Welinder, V. Kumar, and W. Zaremba, <a href="https://arxiv.org/abs/1802.09464">Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research</a>, <em>arXiv:1802.09464</em>, February 2018 [<a href="publications/2018_Plappert_MultiGoalRL.pdf">pdf</a>, <a href="https://blog.openai.com/ingredients-for-robotics-research/">blog post</a>, <a href="https://github.com/openai/gym/tree/master/gym/envs/robotics">code</a>, <a href="publications/2018_Plappert_MultiGoalRL.bib">bib</a>]
          </li>
          <li>
            <strong>M. Plappert</strong>, C. Mandery, and T. Asfour, <a href="https://doi.org/10.1089/big.2016.0028">The KIT Motion-Language Dataset</a>, <em>Big Data, Vol. 4, No. 4, pp. 236-252</em>, December 2016 [<a href="publications/2016_Plappert_Big-Data.pdf">pdf</a>, <a href="https://motion-annotation.humanoids.kit.edu/dataset">dataset</a>, <a href="https://github.com/matthiasplappert/motion-annotation-tool">code</a>, <a href="publications/2016_Plappert_Big-Data.bib">bib</a>]
          </li>
          <li>
            C. Mandery, <strong>M. Plappert</strong>, J. Borràs, and T. Asfour, <a href="http://ieeexplore.ieee.org/document/7527910/">Dimensionality Reduction for Whole-Body Human Motion Recognition</a>, <em>19th International Conference on Information Fusion (FUSION), pp. 355-362</em>, July 2016 [<a href="publications/2016_Mandery_FUSION.pdf">pdf</a>, <a href="publications/2016_Mandery_FUSION.bib">bib</a>]
          </li>
        </ul>
      </div>

      <div class="row">
        <h2>Theses</h2>
        <ul>
          <li>
            <strong>M. Plappert</strong>, Parameter Space Noise for Exploration in Deep Reinforcement Learning, <em>Master thesis</em>, November 2017 [<a href="publications/2017_Plappert_Master-thesis.pdf">pdf</a>, <a href="publications/2017_Plappert_Master-thesis.bib">bib</a>]
          </li>
          <li>
            <strong>M. Plappert</strong>, <a href="http://services.bibliothek.kit.edu/primo/start.php?recordid=KITSRC44651960X">Classification of Human Whole-Body Motion using Hidden Markov Models</a>, <em>Bachelor thesis</em>, August 2015 [<a href="publications/2015_Plappert_Bachelor-thesis.pdf">pdf</a>, <a href="https://github.com/matthiasplappert/motion-classification">code</a>, <a href="publications/2015_Plappert_Bachelor-thesis.bib">bib</a>]
          </li>
        </ul>
      </div>

      <div class="row">
        <h2>Talks</h2>
        <ul>
          <li>
            <a href="https://www.meetup.com/de-DE/karlsruhe-ai/events/254141416/">Learning Dexterity</a>, <em><a href="https://sites.google.com/view/deep-rl-workshop-nips-2018/home">Deep Reinforcement Learning Workshop – NeurIPS 2018</a></em>, December 2018 [<a href="talks/2018-12-neurips-learning-dexterity-slides.pdf">slides</a>, <a href="talks/2018-12-neurips-learning-dexterity-poster.pdf">poster</a>]
          </li>
          <li>
            <a href="https://www.meetup.com/de-DE/karlsruhe-ai/events/254141416/">Learning Dexterity</a>, <em>karlsruhe.ai / Hack &amp; Söhne</em>, September 2018 [<a href="talks/2018-09-06-learning-dexterity.pdf">slides</a>]
          </li>
          <li>
            <a href="https://www.meetup.com/Heidelberg-Artificial-Intelligence-Meetup/events/249605800/">Parameter Space Noise for Exploration</a>, <em>heidelberg.ai</em>, May 2018 [<a href="slides/2018-05-15-param-noise.pdf">slides</a>]
          </li>
        </ul>
      </div>

      <div class="row">
        <h2>Projects</h2>
        <ul>
          <li>
            <a href="https://github.com/keras-rl/keras-rl">Keras-RL</a>, a deep reinforcement learning library for Keras [<a href="http://keras-rl.readthedocs.io/en/latest/">docs</a>]
          </li>
          <li>
            <a href="https://github.com/matthiasplappert/pibot">PiBot</a>, a simple robot platform based on a Raspberry Pi
          </li>
          <li>
            <a href="https://github.com/matthiasplappert/motion-annotation-tool">Motion Annotation Tool</a>, a web-based tool to collect natural language descriptions of human whole-body motion [<a href="https://motion-annotation.humanoids.kit.edu">website</a>]
          </li>
        </ul>
      </div>

      <div class="row">
        <h2>Coverage</h2>
        <ul>
          <li>
            Learning Dexterous In-Hand Manipulation:
            <ul class="comma-separated">
              <li><strong><a href="https://www.nytimes.com/interactive/2018/07/30/technology/robot-hands.html">New York Times</a></strong></li>
              <li><strong><a href="https://www.wired.com/story/this-robot-hand-taught-itself-how-to-grab-stuff-like-a-human/">WIRED</a></strong></li>
              <li><strong><a href="https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/openai-demonstrates-complex-manipulation-transfer-from-simulation-to-real-world">IEEE Spectrum</a></strong></li>
              <li><strong><a href="http://www.sciencemag.org/news/2018/07/watch-robot-hand-learn-manipulate-objects-just-human-hand">Science</a></strong></li>
              <li><a href="https://www.technologyreview.com/s/611724/artificial-intelligence-driven-robot-hand-spends-a-hundred-years-teaching-itself-to-rotate/">MIT Technology Review</a></li>
              <li><a href="https://www.telegraph.co.uk/technology/2018/07/31/robot-breakthrough-elon-musks-ai-group-creates-human-like-hand/">The Telegraph</a></li>
              <li><a href="https://www.bloomberg.com/news/articles/2018-07-31/a-robotic-hand-can-juggle-a-cube-with-lots-of-training">Bloomberg</a></li>
              <li><a href="https://www.sfchronicle.com/business/technology/article/A-robotic-hand-can-juggle-a-cube-with-lots-of-13119510.php">San Francisco Chronicle</a></li>
              <li><a href="https://www.theregister.co.uk/2018/07/30/openai_robot_hand/">The Register</a></li>
              <li><a href="https://apnews.com/64952b7ea20342fc9ccaceb85bbb2f61">Associated Press</a></li>
              <li><a href="https://uk.reuters.com/article/us-robotics-openai/robot-hand-learns-real-world-moves-in-virtual-training-idUKKBN1KK1XG">Reuters</a></li>
              <li><a href="https://www.theverge.com/2018/7/30/17621112/openai-robot-dexterity-dactyl-artificial-intelligence">The Verge</a></li>
              <li><a href="https://www.axios.com/robot-hand-is-breakthrough-for-more-capable-ai-f2745640-8cc4-4941-96ac-2472da52b536.html">Axios</a></li>
              <li><a href="https://techcrunch.com/2018/07/30/openais-robotic-hand-doesnt-need-humans-to-teach-it-human-behaviors/">TechCrunch</a></li>
              <li><a href="https://www.engadget.com/2018/07/30/openai-dactyl-improves-dexterity-robot-hands/">Engadget</a></li>
              <li><a href="https://futurism.com/openai-general-purpose-algorithms/">Futurism</a></li>
              <li><a href="https://www.golem.de/news/openai-roboterhand-erhaelt-feinmotorik-dank-ki-1807-135767.html">golem.de</a></li>
              <li><a href="https://www.spektrum.de/news/binnen-hundert-jahren-gelernt/1582772">Spektrum.de</a></li>
            </ul>
          </li>
          <li>
            Ingredients for Robotics Research:
            <ul class="comma-separated">
              <li><strong><a href="https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/openai-releases-algorithm-that-helps-robots-learn-from-hindsight">IEEE Spectrum</a></strong></li>
              <li><strong><a href="https://www.technologyreview.com/the-download/610394/theres-a-new-way-to-have-robots-learn-from-their-mistakes/">MIT Technology Review</a></strong></li>
              <li><a href="https://www.theregister.co.uk/2018/02/26/openai_gym_robotics/">The Register</a></li>
              <li><a href="http://www.newsweek.com/algorithm-lets-ai-learn-mistakes-830358">Newsweek</a></li>
              <li><a href="https://futurism.com/ai-learn-mistakes-openai">Futurism</a></li>
            </ul>
          </li>
        </ul>
      </div>
    </div>
  </body>
</html>
